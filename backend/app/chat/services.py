from composio import Composio  # type: ignore
from app.chat.agent.PlannerAgent import PlannerAgent  # type: ignore
from app.chat.agent.prompts import PLANNER_AGENT_PROMPT
from app.chat.agent.OpenAIClient import OpenAIClient
from app.chat.agent.MCP.client import MCPClient
from app.chat.agent.schemas import InitialResponse, Plan, PlannerTask, ToolCall
from typing import AsyncGenerator
from openai import OpenAI
from dotenv import load_dotenv
from pathlib import Path
import os

load_dotenv(Path("../../.env"))


class ChatService:
    def __init__(
        self,
    ):
        self.planner: PlannerAgent = None
        self.mcp_client: MCPClient = None
        self.llm: OpenAI = None
        self.tools = None
        self.model_name: str = "gpt-4.1-mini"
        self.composio = Composio()
        self.user_id = "0000-1111-2222"
        self.tool_call_history: list = []
        self.previous_task_results: list = [
            {
                "task_id": "0",
                "task": "first task, no previous task yet",
                "results": "first task, no results yet",
            }
        ]

    async def print_task(self, task: PlannerTask):
        """Print the given task generated by the planner agent

        Args:
            task: The task to print.
            previous_task_results: The results of the previous task.

        Returns:
            None
        """
        yield f"""
            Executing task:

            Task ID: {task.id}
            Task description: {task.description}
            Task Thought: {task.thought}
            Tool calls: {task.tool_calls}
            Task status: {task.status}
            Previous Task Results: {self.previous_task_results}
            """

    async def print_tool_calll(self, tool_call: dict):
        """Print the given tool call generated by the planner agent

        Args:
            tool_call: The tool call to print.

        Returns:
            None
        """
        yield f"""
            Calling Tool:

            Tool Name: {tool_call["name"]}
            Arguments: {tool_call["arguments"]}
            """

    def format_tasks_results_markdown(self) -> str:
        """Format the task results as markdown

        Args:
            task_results: The task results to format.

        Returns:
            str: The formatted task results as markdown.
        """
        output = []
        for i in range(len(self.previous_task_results)):
            task_result = self.previous_task_results[i]
            task_result_formated = f""" 
                    ## Task id: {task_result["task_id"]}
                    - **Task** {task_result["task"]}
                    - **Result:** {task_result["results"]}  
                    """
            output.append(task_result_formated)
        return "\n".join(output)

    async def print_plan(self, plan: Plan):
        """Print the given plan generated by the planner agent

        Args:
            plan: The plan to print.

        Returns:
            None
        """
        yield f"""
                Plan to execute is: \n
                Plan ID: {plan.original_query}
                Plan Description: {plan.description}
            """

    async def call_tools(
        self, tool_calls: list[dict]
    ) -> AsyncGenerator[list[dict], None]:
        """Receives a list of tool calls and calls the tools

        Args:
            tool_calls: Either a list of tool call dicts or a string error message

        Returns:
            list[dict]: The results of the tool calls or error information
        """
        # If we received an error message instead of tool calls
        if isinstance(tool_calls, str):
            return [{"error": True, "message": tool_calls}]

            # # Ensure tool_calls is a list
        if not isinstance(tool_calls, list):
            return [
                {
                    "error": True,
                    "message": f"Expected list of tool calls, got {type(tool_calls).__name__}",
                }
            ]
        results = []  # Tool call results
        print("CALLING_TOOLS ... ")
        for tool in tool_calls:  # For each tool
            try:  # Try to call the tool
                if not isinstance(tool, dict):  # If tool is not a dict return error
                    results.append(
                        {
                            "error": True,
                            "message": f"Expected dict, got {type(tool).__name__}",
                        }
                    )
                    continue
                    # Extract tool name and arguments
                name = tool["name"]
                arguments = tool["arguments"]
                self.print_tool_calll(tool)
                if not name:
                    results.append(
                        {"error": True, "message": "Tool call missing 'name' field"}
                    )
                    continue

                    # Call the tool through MCP client
                result = await self.mcp_client.call_tool(name, arguments)
                # append tool call reults. Includes name, arguments, and result
                results.append({"result": result})
                self.tool_call_history.append(
                    {
                        "name": name,
                        "arguments": arguments,
                        "result": result,
                        "error": False,
                    }
                )

                # Handle exceptions
            except Exception as e:
                print("AT EXCEPTION")
                results.append(
                    {
                        "error": True,
                        "name": name if "name" in locals() else "unknown",
                        "message": f"Error calling tool: {str(e)}",
                    }
                )
        print(f"TOOL CALL RESULTS: {results}")
        return results

    async def execute_task(self, task: PlannerTask) -> AsyncGenerator[list[dict], None]:
        """Execute the given task generated by the planner agent

        Args:
            task: The task to execute.

        Returns:
            A list of results

        """
        # print current task
        self.print_task(task)
        tool_calls = []  # list to hold tool_calls in current task
        for i in range(len(task.tool_calls)):  # for every tool call in the task
            tool_call = task.tool_calls[i]  # select the tool call
            tools = self.extract_tools(
                tool_call
            )  # extract the tool into {name: tool_name, arguments: {...}
            tool_calls.append(tools)  # add tool to tool_Calls list

        print(f"TOOL_CALLS: {tool_calls}")
        tool_call_results = await self.call_tools(
            tool_calls
        )  # call the tools, should return [{'result': result} ...]
        results = [
            result["result"] for result in tool_call_results if "result" in result
        ]  # get the results only

        return results

    def extract_tools(self, tool_call: ToolCall) -> dict:
        """
        Extracts tool name and its arguments from a tool_call object,
        and returns a dictionary with the tool name and arguments
        Args:
            tool_call: ToolCall object
        Returns:
            dict: Dictionary with tool name and arguments
        """
        name = tool_call.name.split(".")[-1]
        tool = {"name": name, "arguments": {}}
        keys = tool_call.arguments.keys
        values = tool_call.arguments.values
        if len(keys) != len(values):
            raise ValueError(
                f"Tool call argument mismatch: keys={keys}, values={values}"
            )
        for key, value in zip(keys, values):
            # --- Tool-specific overrides ---
            if name in ("review_tool", "assemble_content") and key == "content":
                tool["arguments"]["content"] = self.format_tasks_results_markdown()
            elif name == "writer_tool":
                if key == "content":
                    tool["arguments"]["context"] = self.format_tasks_results_markdown()
                elif key == "query":
                    tool["arguments"]["query"] = value
                else:
                    tool["arguments"][key] = value
            elif name == "save_txt":
                if key == "text":
                    tool["arguments"]["text"] = str(self.previous_task_results)
                elif key == "filename":
                    tool["arguments"]["filename"] = value
                else:
                    tool["arguments"][key] = value
            # --- Default fallback ---
            else:
                tool["arguments"][key] = value
        return tool

    async def execute_plan(self, plan: Plan) -> AsyncGenerator[str, None]:
        """Execute the given plan generated by the planner agent
        Args:
            plan: The plan to execute.
        Returns:
            A list of results
        """
        print(f"Executing plan: {plan}")
        print(f"plan dir: {dir(plan)}")
        print()
        self.print_plan(plan)  # print the plan
        results = [
            {
                "task": "No task yet",
                "results": "No task results yet",
            }
        ]  # list to hold results of each task execution.
        for i in range(len(plan.tasks)):  # iterate through tasks
            task: PlannerTask = plan.tasks[i]  # select the task
            res = await self.execute_task(task)  # execute task
            # append task execution results to list
            self.previous_task_results.append(
                {
                    "task_id": task.id,
                    "task": task.description,
                    "results": res,
                }
            )
        return results

    async def process_message(self, user_message):
        """
        Process a user message using the agent's multiple_tool_calls_with_thinking logic.
        Returns structured response data for the frontend.
        """
        print("Initializing MCP client ...")
        self.mcp_client = MCPClient()
        await self.mcp_client.connect()

        print("Getting tools from MCP ...")
        self.tools = await self.mcp_client.get_tools()
        print(f"Loaded {len(self.tools)} tools from MCP")
        print(f"Tools: {self.tools} \n")
        print("\n=== CHAT SERVICE: Processing new message ===")
        print(f"User message: {user_message}")
        print(f"Model: {self.model_name}")

        print("Initializing OpenAI client ...")
        self.llm = OpenAIClient(api_key=os.getenv("OPENAI_API_KEY")).get_client()

        print("Initializing Planner Agent ...")
        self.planner = PlannerAgent(
            dev_prompt=PLANNER_AGENT_PROMPT,
            llm=self.llm,
            messages=[],
            tools=self.tools,
            model_name="gpt-4.1-mini",
        )

        try:
            # Initial request (same structure as agent.py)
            print("\n--- Making initial API call to Claude ---")

            response = self.llm.responses.parse(
                model=self.model_name,
                input=[{"role": "user", "content": user_message}],
                text_format=InitialResponse,
            )

            print(f"Initial response content blocks: {len(response.output)}")

            # Process the response and handle tool calls
            conversation_history = [{"role": "user", "content": user_message}]
            print(
                f"Starting conversation history with {len(conversation_history)} messages"
            )
            # create a plan
            plan = self.planner.plan(user_message)
            plan_parsed = plan.output_parsed
            final_response = await self._handle_response_chain(
                plan_parsed, response, conversation_history
            )

            print("\n=== CHAT SERVICE: Processing complete ===")

            return {"success": True, "response": final_response}

        except Exception as e:
            print("\n!!! CHAT SERVICE ERROR !!!")
            print(f"Error type: {type(e).__name__}")
            print(f"Error message: {str(e)}")
            import traceback

            print(f"Traceback: {traceback.format_exc()}")
            return {"success": False, "error": str(e)}

    async def _handle_response_chain(self, plan, response, conversation_history):
        """
        Handle the full response chain including tool calls, following agent.py logic.
        Returns structured response data.
        """
        print("\n--- Starting response chain handling ---")
        # response_blocks = []
        # iteration = 0

        async for log in self.execute_plan(plan):
            yield log
        # res: list[dict] = await executor.execute_plan(plan)
        final_results = self.previous_task_results[-1]["results"]
        final_message = f"\nFINAL RESPONSE:\n{final_results}"
        yield final_message
